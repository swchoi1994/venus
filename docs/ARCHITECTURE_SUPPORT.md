# Venus Architecture Support

Venus supports an extensive range of both **LLM model architectures** and **CPU hardware architectures**, making it truly universal.

## ü§ñ LLM Model Architectures (45+ Supported)

Venus supports all transformer architectures that vLLM supports and more:

### Language Models
- **LlamaForCausalLM** - Llama 1/2/3 family (7B, 13B, 30B, 65B, 70B)
- **Qwen2ForCausalLM** - Qwen/Qwen2.5 series (0.5B, 1.8B, 7B, 14B, 32B, 72B)
- **MistralForCausalLM** - Mistral models (7B)
- **MixtralForCausalLM** - Mixture of Experts (8x7B, 8x22B)
- **FalconForCausalLM** - Falcon series (7B, 40B, 180B)
- **GPT2/GPTJForCausalLM** - GPT family
- **PhiForCausalLM** - Microsoft Phi series
- **GemmaForCausalLM** - Google Gemma models
- **DeepseekForCausalLM** - Deepseek models
- **Exaone4ForCausalLM** - Exaone models

### Vision-Language Models
- **LlamaForConditionalGeneration** - Llama-3.2-11B-Vision
- **Qwen2VLForConditionalGeneration** - Qwen2-VL series
- **VoxtralForConditionalGeneration** - Multimodal models

### Code Models
- **CodeGenForCausalLM** - Salesforce CodeGen
- **StarCoderForCausalLM** - StarCoder/StarCoder2
- **GPTBigCodeForCausalLM** - BigCode models

### Specialized Models
- **ChatGLMForCausalLM** - Chinese language models
- **BaichuanForCausalLM** - Baichuan series
- **CommandRForCausalLM** - Cohere Command-R
- **MambaForCausalLM** - State-space models
- And 25+ more architectures...

## üíª CPU Hardware Architectures (15+ Supported)

Venus runs on virtually any CPU architecture:

### Desktop/Server CPUs
- **x86_64** - Intel/AMD processors with AVX2/AVX-512
- **Apple Silicon** - M1/M2/M3/M4 with Accelerate framework
- **ARM64/AArch64** - ARM servers, Graviton, Ampere

### Embedded/Mobile CPUs
- **MIPS/MIPS64** - Routers, embedded systems, gaming consoles
  - Supports MSA (MIPS SIMD Architecture) when available
- **PowerPC/PowerPC64** - IBM servers, older Macs, gaming consoles
  - Supports AltiVec/VSX vector extensions
- **SPARC/SPARC64** - Oracle/Sun servers, enterprise systems
  - Supports VIS (Visual Instruction Set) extensions
- **RISC-V** - Open-source processors
  - Supports V extension when available

### Specialized Architectures
- **LoongArch64** - Chinese Loongson processors
  - Supports LSX/LASX vector extensions
- **s390x** - IBM mainframes
  - Supports z/Architecture vector facility
- **WebAssembly** - Browser-based execution
  - Supports WASM SIMD128

## üìä Memory Requirements by Model Size

With Venus's efficient memory management and quantization:

| Model Size | FP32 (Full) | INT8 (Quantized) | Example Models |
|------------|-------------|------------------|----------------|
| 0.5B       | 2 GB        | 0.5 GB          | Qwen2.5-0.5B  |
| 1-3B       | 4-12 GB     | 1-3 GB          | Phi-2, StableLM |
| 7B         | 28 GB       | 7-8 GB          | Llama-2-7B, Mistral-7B |
| 13B        | 52 GB       | 13-15 GB        | Llama-2-13B |
| 30B        | 120 GB      | 30-35 GB        | Llama-30B |
| 70B        | 280 GB      | 70-80 GB        | Llama-2-70B |

## üöÄ Platform-Specific Optimizations

Venus automatically detects and uses platform-specific optimizations:

### Intel/AMD x86_64
```c
// Automatic AVX2/AVX-512 detection
if (has_avx512) {
    use_avx512_gemm();  // 2x faster matrix multiplication
} else if (has_avx2) {
    use_avx2_gemm();    // 1.5x faster
}
```

### Apple Silicon
```c
// Uses Accelerate framework
cblas_sgemm(...);  // Hardware-accelerated BLAS
vDSP_vadd(...);    // Optimized vector operations
```

### ARM64
```c
// NEON SIMD optimizations
float32x4_t vec_mul_neon(float32x4_t a, float32x4_t b);
```

### PowerPC
```c
// AltiVec vector operations
vector float vec_madd(vector float a, vector float b, vector float c);
```

## üîß Building for Different Architectures

Venus automatically detects your platform during build:

```bash
# Generic build (works everywhere)
make

# Cross-compile for MIPS
CC=mips-linux-gnu-gcc make PLATFORM=mips

# Cross-compile for PowerPC
CC=powerpc-linux-gnu-gcc make PLATFORM=powerpc

# WebAssembly build
emcc -O3 src/c/*.c -o venus.wasm -s WASM=1 -s SIMD=1
```

## üìà Performance Expectations

Performance varies by architecture and model:

| Platform | 7B Model Speed | Notes |
|----------|----------------|-------|
| Apple M2 Pro | 30-40 tok/s | With Accelerate |
| Intel i9 (AVX-512) | 25-35 tok/s | With MKL |
| AMD EPYC | 20-30 tok/s | With OpenBLAS |
| ARM Graviton3 | 15-25 tok/s | With NEON |
| PowerPC POWER9 | 10-20 tok/s | With VSX |
| MIPS64 | 5-10 tok/s | Generic ops |
| WebAssembly | 3-5 tok/s | Browser-based |

## üåç Why This Matters

Venus's universal architecture support means:

1. **Run Anywhere**: From supercomputers to embedded devices
2. **No Vendor Lock-in**: Not tied to NVIDIA CUDA or specific hardware
3. **Future-Proof**: Easy to add new architectures
4. **Cost-Effective**: Use existing hardware, no GPU required
5. **Edge Deployment**: Run on routers, IoT devices, browsers

Whether you're running on a massive IBM POWER server, an embedded MIPS router, or in a web browser via WebAssembly, Venus provides consistent, optimized LLM inference across all platforms!